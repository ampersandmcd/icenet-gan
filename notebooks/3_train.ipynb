{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages used in this notebook\n",
    "# add importable modules from src to system path for use in this notebook\n",
    "import os\n",
    "import sys\n",
    "src_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "import src\n",
    "\n",
    "# propagate changes from src into loaded module as we edit\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport src"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "We'll continue by training IceNet with our baseline UNet and new GAN architectures in this notebook.\n",
    "\n",
    "Note that most of the magic here happens behind the scenes!\n",
    "\n",
    "See the following files to get a deeper look into the mechanics behind each script call we make in this notebook.\n",
    "- `src/train_icenet.py`\n",
    "- `src/models.py`\n",
    "- `src/metrics.py`\n",
    "- `src/utils.py`\n",
    "\n",
    "In addition to our aforementioned alignment with the [`icenet-paper` repository](https://github.com/tom-andersson/icenet-paper), we note that the PyTorch Lightning training logic is inspired by Joshua Dimasaka, Andrew McDonald, Meghan Plumridge, Jay Torry, and\n",
    "Andrés Camilo Zúñiga González's [`sea-ice-classification` repository](https://github.com/ai4er-cdt/sea-ice-classification)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configure training arguments\n",
    "When running `src/train_icenet.py` from bash, we can specify training arguments using the usual `--variable=value` flag syntax.\n",
    "\n",
    "When running from this notebook, we'll instead specify our training arguments using a manually constructed `Namespace` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Namespace(\n",
    "            name=\"default\",\n",
    "            model=\"unet\",\n",
    "            criterion=\"ce\",\n",
    "            dataloader_config=\"2023_06_24_1235_icenet_gan.json\",\n",
    "            accelerator=\"auto\",\n",
    "            devices=1,\n",
    "            n_workers=8,\n",
    "            filter_size=3,\n",
    "            n_filters_factor=1.0,\n",
    "            learning_rate=1e-4,\n",
    "            batch_size=8,\n",
    "            seed=42,\n",
    "            precision=32,\n",
    "            log_every_n_steps=10,\n",
    "            max_epochs=100,\n",
    "            num_sanity_val_steps=1,\n",
    "            limit_train_batches=1.0,\n",
    "            limit_val_batches=1.0,\n",
    "            n_to_visualise=3,\n",
    "            fast_dev_run=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the data generator's random seed to 42\n",
      "Checking forecast start dates for missing SIC dates... Setting up the variable paths for dataset_no_cmip... Done.\n",
      "Setting the number of input months for each input variable.\n",
      "Loading and augmenting the polar holes... Done in 0s.\n",
      "\n",
      "on_epoch_end called\n",
      "Setup complete.\n",
      "\n",
      "Setting the data generator's random seed to 42\n",
      "Checking forecast start dates for missing SIC dates... Setting up the variable paths for dataset_no_cmip... Done.\n",
      "Setting the number of input months for each input variable.\n",
      "Loading and augmenting the polar holes... Done in 0s.\n",
      "\n",
      "on_epoch_end called\n",
      "Setup complete.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrewmcdonald\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/users/anddon76/icenet/icenet-gan/notebooks/wandb/run-20230626_103341-bkos00r1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrewmcdonald/icenet-gan/runs/bkos00r1' target=\"_blank\">usual-yogurt-1</a></strong> to <a href='https://wandb.ai/andrewmcdonald/icenet-gan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrewmcdonald/icenet-gan' target=\"_blank\">https://wandb.ai/andrewmcdonald/icenet-gan</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrewmcdonald/icenet-gan/runs/bkos00r1' target=\"_blank\">https://wandb.ai/andrewmcdonald/icenet-gan/runs/bkos00r1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/anddon76/micromamba/envs/icenet-gan/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Trainer' has no attribute 'from_argparse_args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src\u001b[39m.\u001b[39;49mtrain_icenet(args)\n",
      "File \u001b[0;32m~/icenet/icenet-gan/src/train_icenet.py:74\u001b[0m, in \u001b[0;36mtrain_icenet\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     67\u001b[0m wandb_logger\u001b[39m.\u001b[39mexperiment\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(args)\n\u001b[1;32m     69\u001b[0m \u001b[39m# comment/uncomment the following line to track gradients\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m# note that wandb cannot parallelise across multiple gpus when tracking gradients\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# wandb_logger.watch(model, log=\"all\", log_freq=10)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[39m# set up trainer configuration\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer\u001b[39m.\u001b[39;49mfrom_argparse_args(args)\n\u001b[1;32m     75\u001b[0m trainer\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m wandb_logger\n\u001b[1;32m     76\u001b[0m trainer\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mappend(ModelCheckpoint(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Trainer' has no attribute 'from_argparse_args'"
     ]
    }
   ],
   "source": [
    "src.train_icenet(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
