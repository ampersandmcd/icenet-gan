{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/anddon76/icenet/icenet-gan/notebooks\n"
     ]
    }
   ],
   "source": [
    "# import all packages used in this notebook\n",
    "# add importable modules from src to system path for use in this notebook\n",
    "import os\n",
    "import sys\n",
    "src_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "import src\n",
    "import wandb\n",
    "from torchvision.ops.focal_loss import sigmoid_focal_loss\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast\n",
    "Let's continue by generating forecasts with trained models in this notebook.\n",
    "\n",
    "As before, we maintain alignment with the [`icenet-paper` repository](https://github.com/tom-andersson/icenet-paper)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Construct test dataset\n",
    "We'll need data to make a forecast. Let's load our held-out test data to evaluate our models' capacity for generalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the data generator's random seed to 42\n",
      "Checking forecast start dates for missing SIC dates... Setting up the variable paths for dataset_no_cmip... Done.\n",
      "Setting the number of input months for each input variable.\n",
      "Loading and augmenting the polar holes... Done in 0s.\n",
      "\n",
      "on_epoch_end called\n",
      "Setup complete.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Timestamp('2018-02-01 00:00:00'),\n",
       " Timestamp('2018-03-01 00:00:00'),\n",
       " Timestamp('2018-04-01 00:00:00'),\n",
       " Timestamp('2018-05-01 00:00:00'),\n",
       " Timestamp('2018-06-01 00:00:00'),\n",
       " Timestamp('2018-07-01 00:00:00'),\n",
       " Timestamp('2018-08-01 00:00:00'),\n",
       " Timestamp('2018-09-01 00:00:00'),\n",
       " Timestamp('2018-10-01 00:00:00'),\n",
       " Timestamp('2018-11-01 00:00:00'),\n",
       " Timestamp('2018-12-01 00:00:00'),\n",
       " Timestamp('2019-01-01 00:00:00'),\n",
       " Timestamp('2019-02-01 00:00:00'),\n",
       " Timestamp('2019-03-01 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-05-01 00:00:00'),\n",
       " Timestamp('2019-06-01 00:00:00')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = src.IceNetDataset(f\"{src.dataloader_config_folder}/2023_06_24_1235_icenet_gan.json\", mode=\"test\")\n",
    "test_dataset.obs_forecast_IDs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load trained models\n",
    "We'll also need our trained models to make forecasts.\n",
    "\n",
    "Our best gan training run is [here](https://wandb.ai/andrewmcdonald/icenet-gan/runs/wq09bzy7/overview?workspace=user-andrewmcdonald) with colloquial name `radiant-sponge-59-great-unet` and hash name `wq09bzy7`.\n",
    "\n",
    "Our best GAN training run is [here](https://wandb.ai/andrewmcdonald/icenet-gan/runs/4iuiyi32/overview?workspace=user-andrewmcdonald) with colloquial name `stilted-armadillo-99-great-onestep-gan` and hash name `4iuiyi32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "unet_name = \"wq09bzy7\"\n",
    "unet_run = api.run(f\"{src.config.WANDB_USERNAME}/icenet-gan/{unet_name}\")\n",
    "gan_name = \"4iuiyi32\"\n",
    "gan_run = api.run(f\"{src.config.WANDB_USERNAME}/icenet-gan/{gan_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'default',\n",
       " 'seed': 42,\n",
       " 'model': 'unet',\n",
       " 'devices': 1,\n",
       " 'criterion': 'focal',\n",
       " 'n_workers': 8,\n",
       " 'precision': 16,\n",
       " 'batch_size': 10,\n",
       " 'max_epochs': 100,\n",
       " 'accelerator': 'auto',\n",
       " 'filter_size': 3,\n",
       " 'fast_dev_run': False,\n",
       " 'learning_rate': 0.0001,\n",
       " 'n_to_visualise': 1,\n",
       " 'n_filters_factor': 1,\n",
       " 'dataloader_config': '2023_06_24_1235_icenet_gan.json',\n",
       " 'limit_val_batches': 1,\n",
       " 'log_every_n_steps': 10,\n",
       " 'limit_train_batches': 1,\n",
       " 'num_sanity_val_steps': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitUNet(\n",
       "  (model): UNet(\n",
       "    (conv1a): Conv2d(50, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv1b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv2b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv3b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv4b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5a): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv5b): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv6a): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv6b): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv6c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv7a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv7b): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv7c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv8a): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv8b): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv8c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv9a): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv9b): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv9c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (final_conv): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  )\n",
       "  (metrics): MetricCollection(\n",
       "    (val_accuracy): IceNetAccuracy()\n",
       "    (val_accuracy_0): IceNetAccuracy()\n",
       "    (val_accuracy_1): IceNetAccuracy()\n",
       "    (val_accuracy_2): IceNetAccuracy()\n",
       "    (val_accuracy_3): IceNetAccuracy()\n",
       "    (val_accuracy_4): IceNetAccuracy()\n",
       "    (val_accuracy_5): IceNetAccuracy()\n",
       "    (val_sieerror): SIEError()\n",
       "    (val_sieerror_0): SIEError()\n",
       "    (val_sieerror_1): SIEError()\n",
       "    (val_sieerror_2): SIEError()\n",
       "    (val_sieerror_3): SIEError()\n",
       "    (val_sieerror_4): SIEError()\n",
       "    (val_sieerror_5): SIEError()\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (test_accuracy): IceNetAccuracy()\n",
       "    (test_accuracy_0): IceNetAccuracy()\n",
       "    (test_accuracy_1): IceNetAccuracy()\n",
       "    (test_accuracy_2): IceNetAccuracy()\n",
       "    (test_accuracy_3): IceNetAccuracy()\n",
       "    (test_accuracy_4): IceNetAccuracy()\n",
       "    (test_accuracy_5): IceNetAccuracy()\n",
       "    (test_sieerror): SIEError()\n",
       "    (test_sieerror_0): SIEError()\n",
       "    (test_sieerror_1): SIEError()\n",
       "    (test_sieerror_2): SIEError()\n",
       "    (test_sieerror_3): SIEError()\n",
       "    (test_sieerror_4): SIEError()\n",
       "    (test_sieerror_5): SIEError()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct blank model\n",
    "unet = src.UNet(\n",
    "    input_channels=test_dataset.tot_num_channels,\n",
    "    filter_size=unet_run.config[\"filter_size\"],\n",
    "    n_filters_factor=unet_run.config[\"n_filters_factor\"],\n",
    "    n_forecast_months=test_dataset.config[\"n_forecast_months\"]\n",
    ")\n",
    "\n",
    "# construct criteria\n",
    "if unet_run.config[\"criterion\"] == \"ce\":\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "elif unet_run.config[\"criterion\"] == \"focal\":\n",
    "    criterion = sigmoid_focal_loss  # reduction=\"none\" by default\n",
    "\n",
    "# lightning will load checkpointed weights onto this model\n",
    "unet_best_ckpt = f\"{src.config.WANDB_DIR}/radiant-sponge-59-great-unet/checkpoints/best-epoch=11-step=456.ckpt\"\n",
    "lit_module_unet = src.LitUNet.load_from_checkpoint(unet_best_ckpt, model=unet, criterion=criterion)\n",
    "lit_module_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'default',\n",
       " 'seed': 42,\n",
       " 'model': 'gan',\n",
       " 'sigma': 1,\n",
       " 'devices': 1,\n",
       " 'criterion': 'focal',\n",
       " 'n_workers': 8,\n",
       " 'precision': 16,\n",
       " 'batch_size': 2,\n",
       " 'max_epochs': 100,\n",
       " 'accelerator': 'auto',\n",
       " 'd_lr_factor': 1,\n",
       " 'filter_size': 3,\n",
       " 'fast_dev_run': False,\n",
       " 'learning_rate': 0.0001,\n",
       " 'n_to_visualise': 1,\n",
       " 'generator_lambda': 500,\n",
       " 'n_filters_factor': 1,\n",
       " 'dataloader_config': '2023_06_24_1235_icenet_gan.json',\n",
       " 'limit_val_batches': 1,\n",
       " 'log_every_n_steps': 10,\n",
       " 'discriminator_mode': 'onestep',\n",
       " 'limit_train_batches': 1,\n",
       " 'num_sanity_val_steps': 1,\n",
       " 'discriminator_criterion': 'ce',\n",
       " 'generator_fake_criterion': 'ce',\n",
       " 'generator_structural_criterion': 'ce'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitGAN(\n",
       "  (generator): Generator(\n",
       "    (conv1a): Conv2d(51, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv1b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv2b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv3b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv4b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5a): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv5b): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv6a): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv6b): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv6c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv7a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv7b): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv7c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv8a): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv8b): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv8c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv9a): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv9b): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv9c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (final_conv): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (conv1a): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv1b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv2b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv3b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv4b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5a): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv5b): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (final_conv): Conv2d(1024, 2, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (generator_fake_criterion): BCEWithLogitsLoss()\n",
       "  (generator_structural_criterion): CrossEntropyLoss()\n",
       "  (discriminator_criterion): BCEWithLogitsLoss()\n",
       "  (metrics): MetricCollection(\n",
       "    (val_accuracy): IceNetAccuracy()\n",
       "    (val_accuracy_0): IceNetAccuracy()\n",
       "    (val_accuracy_1): IceNetAccuracy()\n",
       "    (val_accuracy_2): IceNetAccuracy()\n",
       "    (val_accuracy_3): IceNetAccuracy()\n",
       "    (val_accuracy_4): IceNetAccuracy()\n",
       "    (val_accuracy_5): IceNetAccuracy()\n",
       "    (val_sieerror): SIEError()\n",
       "    (val_sieerror_0): SIEError()\n",
       "    (val_sieerror_1): SIEError()\n",
       "    (val_sieerror_2): SIEError()\n",
       "    (val_sieerror_3): SIEError()\n",
       "    (val_sieerror_4): SIEError()\n",
       "    (val_sieerror_5): SIEError()\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (test_accuracy): IceNetAccuracy()\n",
       "    (test_accuracy_0): IceNetAccuracy()\n",
       "    (test_accuracy_1): IceNetAccuracy()\n",
       "    (test_accuracy_2): IceNetAccuracy()\n",
       "    (test_accuracy_3): IceNetAccuracy()\n",
       "    (test_accuracy_4): IceNetAccuracy()\n",
       "    (test_accuracy_5): IceNetAccuracy()\n",
       "    (test_sieerror): SIEError()\n",
       "    (test_sieerror_0): SIEError()\n",
       "    (test_sieerror_1): SIEError()\n",
       "    (test_sieerror_2): SIEError()\n",
       "    (test_sieerror_3): SIEError()\n",
       "    (test_sieerror_4): SIEError()\n",
       "    (test_sieerror_5): SIEError()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct blank models\n",
    "generator = src.Generator(\n",
    "    input_channels=test_dataset.tot_num_channels,\n",
    "    filter_size=gan_run.config[\"filter_size\"],\n",
    "    n_filters_factor=gan_run.config[\"n_filters_factor\"],\n",
    "    n_forecast_months=test_dataset.config[\"n_forecast_months\"]\n",
    ")\n",
    "discriminator = src.Discriminator(\n",
    "    input_channels=test_dataset.tot_num_channels,\n",
    "    filter_size=gan_run.config[\"filter_size\"],\n",
    "    n_filters_factor=gan_run.config[\"n_filters_factor\"],\n",
    "    n_forecast_months=test_dataset.config[\"n_forecast_months\"],\n",
    "    mode=gan_run.config[\"discriminator_mode\"]\n",
    ")\n",
    "\n",
    "# construct criteria\n",
    "generator_fake_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "if gan_run.config[\"generator_structural_criterion\"] == \"l1\":\n",
    "    generator_structural_criterion = nn.L1Loss(reduction=\"none\")\n",
    "elif gan_run.config[\"generator_structural_criterion\"] == \"ce\":\n",
    "    generator_structural_criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "elif gan_run.config[\"generator_structural_criterion\"] == \"focal\":\n",
    "    generator_structural_criterion = sigmoid_focal_loss\n",
    "\n",
    "discriminator_criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "# lightning will load checkpointed weights onto this model\n",
    "gan_best_ckpt = f\"{src.config.WANDB_DIR}/stilted-armadillo-99-great-onestep-gan/checkpoints/best-epoch=7-step=3024-v1.ckpt\"\n",
    "lit_module_gan = src.LitGAN.load_from_checkpoint(\n",
    "    gan_best_ckpt,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    generator_fake_criterion=generator_fake_criterion,\n",
    "    generator_structural_criterion=generator_structural_criterion,\n",
    "    discriminator_criterion=discriminator_criterion\n",
    ")\n",
    "lit_module_gan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pass data through trained models\n",
    "Let's pass our held-out test data through each trained model and visualise the output tensors.\n",
    "\n",
    "We'll check our available GPU memory with `!nvidia-smi` and will enable `torch.no_grad()` to save memory since we won't need gradients in this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_unet = DataLoader(test_dataset, batch_size=unet_run.config[\"batch_size\"], num_workers=8,\n",
    "                                  persistent_workers=True, pin_memory=False, shuffle=False)\n",
    "test_dataloader_gan = DataLoader(test_dataset, batch_size=gan_run.config[\"batch_size\"], num_workers=8,\n",
    "                                  persistent_workers=True, pin_memory=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 27 17:30:06 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A2           On   | 00000000:98:00.0 Off |                    0 |\n",
      "|  0%   37C    P0    19W /  60W |   1382MiB / 15356MiB |     21%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     16480      C   ...icenet-gan/bin/python3.11     1380MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/anddon76/micromamba/envs/icenet-gan/lib/python3.11/site-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17, 432, 432, 3, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass batches through unet and accumulate into list\n",
    "y_hat_unet = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader_unet:\n",
    "        x, y, sample_weight = batch\n",
    "        pred_unet = lit_module_unet(x.to(lit_module_unet.device)).detach().cpu().numpy()\n",
    "        y_hat_unet.extend(pred_unet)\n",
    "y_hat_unet = np.array(y_hat_unet)\n",
    "y_hat_unet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 432, 432, 3, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass batches through gan and accumulate into list\n",
    "y_hat_gan = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader_gan:\n",
    "        x, y, sample_weight = batch\n",
    "        pred_gan = lit_module_gan(x.to(lit_module_gan.device)).detach().cpu().numpy()\n",
    "        y_hat_gan.extend(pred_gan)\n",
    "y_hat_gan = np.array(y_hat_gan)\n",
    "y_hat_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 27 17:30:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A2           On   | 00000000:98:00.0 Off |                    0 |\n",
      "|  0%   44C    P0    45W /  60W |    616MiB / 15356MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     16480      C   ...icenet-gan/bin/python3.11      614MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()  # free pytorch memory\n",
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Format and save forecasts\n",
    "Let's save our forecasts as netCDF files before we move to evaluate them in the next notebook.\n",
    "\n",
    "This will allow us to extend our downstream evaluation methods without needing to load and run our computationally-intensive models each time we want to obtain a forecast.\n",
    "\n",
    "This will also make our forecasts accessible to others who may be interested in sea ice but not in the technical nuances of deep learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. All set\n",
    "With our forecasts safe and sound inside netCDF files, we're clear to move forward.\n",
    "\n",
    "We'll continue by evaluating these forecasts in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
